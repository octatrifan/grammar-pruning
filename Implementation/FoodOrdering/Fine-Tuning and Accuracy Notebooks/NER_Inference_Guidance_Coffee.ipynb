{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "vM9f2Krba6_5",
    "outputId": "2385b8a3-c1a1-464c-dee3-6a23bd059fdc"
   },
   "source": [
    "import guidance\n",
    "from guidance import models, gen, one_or_more, select, zero_or_more, regex, optional, capture\n",
    "\n",
    "model_name = \"your_model_name_here\"\n",
    "\n",
    "model = models.LlamaCpp(f\"{model_name}.gguf\", n_gpu_layers=-1, n_ctx=2048)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SpyQ_wIKbEoj"
   },
   "source": [
    "@guidance(stateless=False)\n",
    "def drinkOrderCoffee(lm):\n",
    "    lm += \"DrinkOrder(\"\n",
    "    lm += select([\"number=\"+regex(\"\\d+\"), \"\"], name='numberFlag')\n",
    "    if drink_type_values:\n",
    "      lm += select([\", drink_type='\" + select(drink_type_values, name='drinkTypeName')+\"'\", \"\"], name='drinkTypeFlag')\n",
    "      if lm['drinkTypeFlag'] != \"\":\n",
    "        drink_type_values.remove(lm['drinkTypeName'])\n",
    "\n",
    "    if roast_type_values:\n",
    "      lm += select([\", roast_type='\"+select(roast_type_values, name='roastTypeName')+\"'\", \"\"], name='drinkTypeFlag')\n",
    "      if lm['drinkTypeFlag'] != \"\":\n",
    "        roast_type_values.remove(lm['roastTypeName'])\n",
    "\n",
    "    if size_values:\n",
    "      lm += select([\", size='\"+select(size_values, name='sizeName')+\"'\", \"\"], name='sizeFlag')\n",
    "      if lm['sizeFlag'] != \"\":\n",
    "        size_values.remove(lm['sizeName'])\n",
    "\n",
    "    if style_values:\n",
    "      lm += select([\", style='\"+select(style_values, name='styleName')+\"'\", \"\"], name='styleFlag')\n",
    "      if lm['styleFlag'] != \"\":\n",
    "        style_values.remove(lm['styleName'])\n",
    "\n",
    "    if topping_values:\n",
    "      lm += select([\", toppings=[\", \"\"], name='toppingsFlag')\n",
    "      if lm['toppingsFlag']:\n",
    "        for i in topping_values[:]:\n",
    "          lm += toppingCoffee()\n",
    "          if not topping_values:\n",
    "            lm += ']'\n",
    "            break\n",
    "          lm += select([\", \", \"]\"], name=\"finishedListToppings\")\n",
    "          if lm['finishedListToppings'] == \"]\":\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "    return lm + \")\"\n",
    "\n",
    "@guidance(stateless=False)\n",
    "def toppingCoffee(lm):\n",
    "  lm += \"Topping(name=\"\n",
    "  if topping_values:\n",
    "    lm += \"'\" + select(topping_values, name='toppingName') + \"'\"\n",
    "    topping_values.remove(lm['toppingName'])\n",
    "\n",
    "  if quantity_values:\n",
    "    lm += select([\", qualifier='\" + select(quantity_values, name='qualifierName') + \"'\", \"\"], name='qualifierFlag')\n",
    "    if lm[\"qualifierFlag\"] != \"\":\n",
    "      quantity_values.remove(lm['qualifierName'])\n",
    "\n",
    "  if not_values:\n",
    "    lm += select([\", negation=True\", \"\"], name='negationFlag')\n",
    "    if lm['negationFlag'] != \"\":\n",
    "      not_values.remove('not')\n",
    "\n",
    "  lm += \")\"\n",
    "  return lm\n",
    "\n",
    "@guidance(stateless=False)\n",
    "def validOrderCoffee(lm):\n",
    "  lm += \"[\"\n",
    "  first = True\n",
    "  for i in range(7):\n",
    "    if drink_type_values:\n",
    "      if not first:\n",
    "        lm += select(\", \", \"\")\n",
    "      else:\n",
    "        first = False\n",
    "\n",
    "      lm += drinkOrderCoffee()\n",
    "    else:\n",
    "      break\n",
    "  return lm +']'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SZwQ3fBfbHnF"
   },
   "source": [
    "instruction_generate_coffee = \"\"\"You are a helpful assistant. You have to take as input a customer order and output a list of the corresponding objects. You should use only the following classes in Python:\n",
    "class Topping:\n",
    "      def __init__(self, name: str, qualifier: Optional[str] = None, negation: Optional[bool] = False) -> None:\n",
    "\n",
    "class DrinkOrder:\n",
    "      def __init__(self, number: int = 1, drink_type: Optional[str] = None, size: Optional[str] = None, style: Optional[str] = None, roast_type: Optional[str] = None, toppings: Optional[List[Topping]] = None) -> None:\n",
    "\n",
    "The output should be a list of those objects.\"\"\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8dWZpodUbqbP"
   },
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy import displacy\n",
    "import os\n",
    "import re\n",
    "\n",
    "def parse_line(line):\n",
    "    parts = line.strip().split('\\t')\n",
    "    if len(parts) != 2:\n",
    "        return None, None\n",
    "\n",
    "    phrase, category = parts\n",
    "\n",
    "    return phrase, category.strip()\n",
    "\n",
    "def init_pipeline(dataset = \"coffee\"):\n",
    "  nlp = spacy.load(\"en_core_web_sm\")\n",
    "  ner_ruler = nlp.add_pipe(\"entity_ruler\",\n",
    "                      before=\"ner\",\n",
    "                      config={\"phrase_matcher_attr\": \"LOWER\"})\n",
    "\n",
    "  def read_file_categories(food_type):\n",
    "      file_path = f\"FoodOrderingDataset/data/{food_type}/alias\"\n",
    "\n",
    "      text_files = [f for f in os.listdir(file_path) if f.endswith('.txt')]\n",
    "\n",
    "      patterns = []\n",
    "\n",
    "      for file in text_files:\n",
    "          path_to_file = f\"{file_path}/{file}\"\n",
    "          with open(path_to_file, 'r') as file:\n",
    "              for line in file:\n",
    "                  if line.strip():\n",
    "                      phrase, category_info = parse_line(line)\n",
    "                      if phrase and category_info:\n",
    "                          schema = {}\n",
    "                          schema[\"pattern\"] = phrase\n",
    "                          schema[\"label\"] = category_info\n",
    "                          patterns.append(schema)\n",
    "\n",
    "      return patterns\n",
    "\n",
    "  category_patterns = read_file_categories(dataset)\n",
    "\n",
    "  ner_ruler.add_patterns(category_patterns)\n",
    "  return nlp\n",
    "\n",
    "\n",
    "nlp = init_pipeline()\n",
    "\n",
    "def process_NER(input_order):\n",
    "    found_categories = []\n",
    "\n",
    "    doc = nlp(input_order)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        found_categories.append((ent.text, ent.label_))\n",
    "\n",
    "    return found_categories"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "p87BpXABbPpa",
    "outputId": "ad855072-afae-4f76-a5ba-c3860dd3bcc5"
   },
   "source": [
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "file_path = f'FoodOrderingDataset/output/{model_name}-coffee-NER.json'\n",
    "\n",
    "existing_data=[]\n",
    "\n",
    "with open('FoodOrderingDataset/processed_data/coffee_dataset.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "input_list = []\n",
    "for obj in data:\n",
    "    input_value = obj.get(\"input\", \"No input key found\")\n",
    "    output_value = obj.get(\"output_extract\", \"No output key found\")\n",
    "    output_generate = obj.get(\"output_generate\", \"No output key found\")\n",
    "    used_items_value = process_NER(input_value)\n",
    "    used_items_value_decoupled = [x[0] + ' - ' + x[1] for x in used_items_value]\n",
    "    used_items_str = ', '.join(used_items_value_decoupled).lower()\n",
    "\n",
    "    input_augmented_file = input_value + \"\\nItems Found: \" + used_items_str\n",
    "    input_list.append((input_value, input_augmented_file, output_generate, used_items_value, used_items_str))\n",
    "\n",
    "for i in range(len(input_list)):\n",
    "    if i > 130:\n",
    "        break\n",
    "    (initial_input, input, expected, used_items_value, used_items_str) = input_list[i]\n",
    "    lm = model + f'''\\\n",
    "    Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "    ### Instruction:\n",
    "    {instruction_generate_coffee}\n",
    "    ### Input:\n",
    "    {input}\n",
    "\n",
    "    ### Response:\n",
    "    '''\n",
    "\n",
    "    items = []\n",
    "    print(used_items_value)\n",
    "    for item in used_items_value:\n",
    "      match = re.search(r'(\\w+)\\(([^)]+)\\)', item[1])\n",
    "      if match:\n",
    "        items.append((match.group(1), match.group(2)))\n",
    "    items_dict = defaultdict(list)\n",
    "    for item_type, item_value in items:\n",
    "        items_dict[item_type.lower()].append(item_value.lower())\n",
    "\n",
    "    print(items_dict)\n",
    "    items_dict = dict(items_dict)\n",
    "    keys_to_extract = ['topping', 'size', 'number', 'drink_type', 'roast_type', 'not', 'style', 'quantity']\n",
    "\n",
    "    for key in keys_to_extract:\n",
    "        globals()[f\"{key}_values\"] = items_dict.get(key, [])\n",
    "        print(key, globals()[f\"{key}_values\"])\n",
    "\n",
    "    ans = lm + capture(validOrderCoffee(), \"answer\")\n",
    "\n",
    "    existing_data.append({\"input\":initial_input, \"input_augmented\": input, \"output\": ans[\"answer\"], \"expected\":expected, \"output_NER\": used_items_str})\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(existing_data, file, indent=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def remove_duplicate_toppings(order_str: str) -> str:\n",
    "    pattern = r\"(toppings=\\[)(.*?)(\\])\"\n",
    "    \n",
    "    def dedupe(match: re.Match) -> str:\n",
    "        prefix = match.group(1)\n",
    "        content = match.group(2)\n",
    "        suffix = match.group(3)\n",
    "        \n",
    "        topping_pattern = r\"Topping\\([^)]*\\)\"\n",
    "        topping_items = re.findall(topping_pattern, content)\n",
    "        \n",
    "        seen = set()\n",
    "        unique_toppings = []\n",
    "        for item in topping_items:\n",
    "            if item not in seen:\n",
    "                seen.add(item)\n",
    "                unique_toppings.append(item)\n",
    "        \n",
    "        new_content = \", \".join(unique_toppings)\n",
    "        return f\"{prefix}{new_content}{suffix}\"\n",
    "    \n",
    "    cleaned_str = re.sub(pattern, dedupe, order_str, flags=re.DOTALL)\n",
    "    if cleaned_str[-4:] != \")])]\" and \"Topping\" in cleaned_str: cleaned_str += \")]\"\n",
    "    return cleaned_str"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSWFR2mo__ut",
    "outputId": "c0f086f5-98d7-4e8c-b703-0a90952b4ee3"
   },
   "source": [
    "import json\n",
    "\n",
    "def calculate_accuracy_and_save_mismatches(json_file, output_file):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    total = len(data)\n",
    "    correct = 0\n",
    "    mismatches = []\n",
    "\n",
    "    for item in data:\n",
    "        output = item['output']\n",
    "        expected = item['expected'].lower()\n",
    "\n",
    "        output = remove_duplicate_toppings(output).lower()\n",
    "\n",
    "        if output == expected:\n",
    "            correct += 1\n",
    "        else:\n",
    "            print('\\n\\n')\n",
    "            print(output)\n",
    "            print(expected)\n",
    "            mismatches.append(item)\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(mismatches, outfile, indent=4)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "json_file = f'FoodOrderingDataset/output/{model_name}-coffee-NER.json'\n",
    "mismatch_file = f'FoodOrderingDataset/output/{model_name}-coffee-NER_processed_mismatches.json'\n",
    "\n",
    "accuracy = calculate_accuracy_and_save_mismatches(json_file, mismatch_file)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Mismatches have been saved to: {mismatch_file}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ACL_Inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
