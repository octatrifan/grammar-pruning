{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "vM9f2Krba6_5",
    "outputId": "2385b8a3-c1a1-464c-dee3-6a23bd059fdc"
   },
   "source": [
    "import guidance\n",
    "from guidance import models, gen, one_or_more, select, zero_or_more, regex, optional, capture\n",
    "\n",
    "model_name = \"your_model_name_here\"\n",
    "\n",
    "model = models.LlamaCpp(f\"{model_name}.gguf\", n_gpu_layers=-1, n_ctx=2048)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SZwQ3fBfbHnF"
   },
   "source": [
    "instruction_generate_coffee = \"\"\"You are a helpful assistant. You have to take as input a customer order and output a list of the corresponding objects. You should use only the following classes in Python:\n",
    "class Topping:\n",
    "      def __init__(self, name: str, qualifier: Optional[str] = None, negation: Optional[bool] = False) -> None:\n",
    "\n",
    "class DrinkOrder:\n",
    "      def __init__(self, number: int = 1, drink_type: Optional[str] = None, size: Optional[str] = None, style: Optional[str] = None, roast_type: Optional[str] = None, toppings: Optional[List[Topping]] = None) -> None:\n",
    "\n",
    "The output should be a list of those objects.\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8dWZpodUbqbP"
   },
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy import displacy\n",
    "import os\n",
    "import re\n",
    "\n",
    "def parse_line(line):\n",
    "    parts = line.strip().split('\\t')\n",
    "    if len(parts) != 2:\n",
    "        return None, None\n",
    "\n",
    "    phrase, category = parts\n",
    "\n",
    "    return phrase, category.strip()\n",
    "\n",
    "def init_pipeline(dataset = \"coffee\"):\n",
    "  nlp = spacy.load(\"en_core_web_sm\")\n",
    "  ner_ruler = nlp.add_pipe(\"entity_ruler\",\n",
    "                      before=\"ner\",\n",
    "                      config={\"phrase_matcher_attr\": \"LOWER\"})\n",
    "\n",
    "  def read_file_categories(food_type):\n",
    "\n",
    "      file_path = f\"FoodOrderingDataset/data/{food_type}/alias\"\n",
    "\n",
    "      text_files = [f for f in os.listdir(file_path) if f.endswith('.txt')]\n",
    "\n",
    "      patterns = []\n",
    "\n",
    "      for file in text_files:\n",
    "          path_to_file = f\"{file_path}/{file}\"\n",
    "          with open(path_to_file, 'r') as file:\n",
    "              for line in file:\n",
    "                  if line.strip():\n",
    "                      phrase, category_info = parse_line(line)\n",
    "                      if phrase and category_info:\n",
    "                          schema = {}\n",
    "                          schema[\"pattern\"] = phrase\n",
    "                          schema[\"label\"] = category_info\n",
    "                          patterns.append(schema)\n",
    "\n",
    "      return patterns\n",
    "\n",
    "  category_patterns = read_file_categories(dataset)\n",
    "\n",
    "  ner_ruler.add_patterns(category_patterns)\n",
    "  return nlp\n",
    "\n",
    "\n",
    "nlp = init_pipeline()\n",
    "\n",
    "def process_NER(input_order):\n",
    "    found_categories = []\n",
    "\n",
    "    doc = nlp(input_order)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        found_categories.append((ent.text, ent.label_))\n",
    "\n",
    "    return found_categories"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "p87BpXABbPpa",
    "outputId": "ad855072-afae-4f76-a5ba-c3860dd3bcc5"
   },
   "source": [
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "file_path = f'FoodOrderingDataset/output/Ablation_NER_Coffee_Results_{model_name}.json'\n",
    "\n",
    "existing_data=[]\n",
    "\n",
    "with open('FoodOrderingDataset/processed_data/coffee_dataset.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "input_list = []\n",
    "for obj in data:\n",
    "    input_value = obj.get(\"input\", \"No input key found\")\n",
    "    output_value = obj.get(\"output_extract\", \"No output key found\")\n",
    "    output_generate = obj.get(\"output_generate\", \"No output key found\")\n",
    "    used_items_value = process_NER(input_value)\n",
    "    used_items_value_decoupled = [x[0] + ' - ' + x[1] for x in used_items_value]\n",
    "    used_items_str = ', '.join(used_items_value_decoupled).lower()\n",
    "\n",
    "    input_augmented_file = input_value + \"\\nItems Found: \" + used_items_str\n",
    "    input_list.append((input_value, input_augmented_file, output_generate, used_items_value, used_items_str))\n",
    "\n",
    "for i in range(len(input_list)):\n",
    "    if i > 130:\n",
    "        break\n",
    "    (initial_input, input, expected, used_items_value, used_items_str) = input_list[i]\n",
    "    lm = model + f'''\\\n",
    "    Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "    ### Instruction:\n",
    "    {instruction_generate_coffee}\n",
    "    ### Input:\n",
    "    {input}\n",
    "\n",
    "    ### Response:\n",
    "    '''\n",
    "\n",
    "    ans = lm + gen(\"answer\", max_tokens=150, stop='\\n')\n",
    "\n",
    "    existing_data.append({\"input\":initial_input, \"input_augmented\": input, \"output\": ans[\"answer\"], \"expected\":expected, \"output_NER\": used_items_str})\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(existing_data, file, indent=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "from operator import lt, gt\n",
    "\n",
    "ROAST_CANDIDATES = {\"cinnamon\"}\n",
    "\n",
    "def clean_topping(topping_str):\n",
    "    m = re.match(r\"Topping\\((.*?)\\)\", topping_str)\n",
    "    if not m:\n",
    "        return topping_str\n",
    "    inner = m.group(1)\n",
    "    parts = [p.strip() for p in inner.split(\",\")]\n",
    "    params = {}\n",
    "    for part in parts:\n",
    "        if \"=\" in part:\n",
    "            key, val = part.split(\"=\", 1)\n",
    "            params[key.strip()] = val.strip()\n",
    "    for key in list(params.keys()):\n",
    "        if params[key] == \"'None'\" or (key == \"negation\" and params[key] == \"False\"):\n",
    "            del params[key]\n",
    "    if \"name\" in params and params[\"name\"].strip(\"'\") == \"espresso_shot\":\n",
    "        return \"Topping(name='ESPRESSO_SHOT_1')\"\n",
    "    if \"name\" in params:\n",
    "        return f\"Topping(name={params['name']})\"\n",
    "    return topping_str\n",
    "\n",
    "def canonicalize_drink_order(order_str):\n",
    "    m = re.match(r\"(DrinkOrder)\\((.*)\\)\", order_str)\n",
    "    if not m:\n",
    "        return order_str\n",
    "    order_type, params_str = m.groups()\n",
    "    params = []\n",
    "    current = \"\"\n",
    "    paren_count = 0\n",
    "    bracket_count = 0\n",
    "    for ch in params_str:\n",
    "        if ch == \"(\":\n",
    "            paren_count += 1\n",
    "        elif ch == \")\":\n",
    "            paren_count -= 1\n",
    "        elif ch == \"[\":\n",
    "            bracket_count += 1\n",
    "        elif ch == \"]\":\n",
    "            bracket_count -= 1\n",
    "        if ch == \",\" and paren_count == 0 and bracket_count == 0:\n",
    "            params.append(current.strip())\n",
    "            current = \"\"\n",
    "        else:\n",
    "            current += ch\n",
    "    if current.strip():\n",
    "        params.append(current.strip())\n",
    "    \n",
    "    param_dict = {}\n",
    "    toppings_list = []\n",
    "    for param in params:\n",
    "        if \"=\" in param:\n",
    "            key, value = param.split(\"=\", 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "            if key == \"toppings\":\n",
    "                inner = value.strip(\"[]\").strip()\n",
    "                if inner:\n",
    "                    tlist = []\n",
    "                    cur = \"\"\n",
    "                    pc = 0\n",
    "                    for c in inner:\n",
    "                        if c == \"(\":\n",
    "                            pc += 1\n",
    "                        elif c == \")\":\n",
    "                            pc -= 1\n",
    "                        if c == \",\" and pc == 0:\n",
    "                            tlist.append(cur.strip())\n",
    "                            cur = \"\"\n",
    "                        else:\n",
    "                            cur += c\n",
    "                    if cur.strip():\n",
    "                        tlist.append(cur.strip())\n",
    "                    for t in tlist:\n",
    "                        cleaned = clean_topping(t)\n",
    "                        toppings_list.append(cleaned)\n",
    "            else:\n",
    "                param_dict[key] = value\n",
    "    for key in list(param_dict.keys()):\n",
    "        if param_dict[key] == \"'None'\":\n",
    "            del param_dict[key]\n",
    "    roast_from_topping = None\n",
    "    new_toppings = []\n",
    "    for t in toppings_list:\n",
    "        m2 = re.match(r\"Topping\\(name=('[^']+')\\)\", t)\n",
    "        if m2:\n",
    "            name_val = m2.group(1).strip(\"'\")\n",
    "            if name_val in ROAST_CANDIDATES:\n",
    "                roast_from_topping = name_val + \"_roast\"\n",
    "                continue\n",
    "        new_toppings.append(t)\n",
    "    if roast_from_topping and \"roast_type\" not in param_dict:\n",
    "        param_dict[\"roast_type\"] = f\"'{roast_from_topping}'\"\n",
    "    \n",
    "    canon_order = [\"number\", \"drink_type\", \"roast_type\", \"size\", \"style\", \"toppings\"]\n",
    "    new_params = []\n",
    "    for key in canon_order:\n",
    "        if key == \"toppings\":\n",
    "            if new_toppings:\n",
    "                new_params.append(\"toppings=[\" + \", \".join(new_toppings) + \"]\")\n",
    "        elif key in param_dict:\n",
    "            new_params.append(f\"{key}={param_dict[key]}\")\n",
    "    return f\"{order_type}(\" + \", \".join(new_params) + \")\"\n",
    "\n",
    "def merge_drink_orders(order_strs):\n",
    "    orders = []\n",
    "    for s in order_strs:\n",
    "        m = re.match(r\"DrinkOrder\\((.*)\\)\", s)\n",
    "        if not m:\n",
    "            continue\n",
    "        params_str = m.group(1)\n",
    "        parts = []\n",
    "        cur = \"\"\n",
    "        bracket_count = 0\n",
    "        for c in params_str:\n",
    "            if c == \"[\":\n",
    "                bracket_count += 1\n",
    "            elif c == \"]\":\n",
    "                bracket_count -= 1\n",
    "            if c == \",\" and bracket_count == 0:\n",
    "                parts.append(cur.strip())\n",
    "                cur = \"\"\n",
    "            else:\n",
    "                cur += c\n",
    "        if cur.strip():\n",
    "            parts.append(cur.strip())\n",
    "        d = {}\n",
    "        for part in parts:\n",
    "            if \"=\" in part:\n",
    "                key, val = part.split(\"=\", 1)\n",
    "                d[key.strip()] = val.strip()\n",
    "        orders.append(d)\n",
    "    \n",
    "    base = None\n",
    "    extra = None\n",
    "    remaining = []\n",
    "    for o in orders:\n",
    "        dt = o.get(\"drink_type\", \"\").strip(\"'\")\n",
    "        if dt == \"espresso\":\n",
    "            extra = o\n",
    "        else:\n",
    "            base = o\n",
    "            remaining.append(o)\n",
    "    if base and extra:\n",
    "        def parse_toppings(t_str):\n",
    "            t_str = t_str.strip(\"[]\")\n",
    "            if not t_str:\n",
    "                return []\n",
    "            return [x.strip() for x in t_str.split(\",\")]\n",
    "        base_tops = parse_toppings(base.get(\"toppings\", \"[]\"))\n",
    "        extra_tops = parse_toppings(extra.get(\"toppings\", \"[]\"))\n",
    "        merged_tops = base_tops + extra_tops\n",
    "        base[\"toppings\"] = \"[\" + \", \".join(merged_tops) + \"]\" if merged_tops else \"\"\n",
    "        if \"style\" not in base and \"style\" in extra:\n",
    "            base[\"style\"] = extra[\"style\"]\n",
    "        merged_order_str = \"DrinkOrder(\" + \", \".join(f\"{k}={v}\" for k, v in base.items() if v and v != \"'None'\") + \")\"\n",
    "        merged = [merged_order_str]\n",
    "        for o in orders:\n",
    "            dt_val = o.get(\"drink_type\", \"\").strip(\"'\")\n",
    "            if dt_val != \"espresso\" and o != base:\n",
    "                merged.append(\"DrinkOrder(\" + \", \".join(f\"{k}={v}\" for k, v in o.items() if v and v != \"'None'\") + \")\")\n",
    "        return merged\n",
    "    else:\n",
    "        merged = []\n",
    "        for o in orders:\n",
    "            merged.append(\"DrinkOrder(\" + \", \".join(f\"{k}={v}\" for k, v in o.items() if v and v != \"'None'\") + \")\")\n",
    "        return merged\n",
    "\n",
    "def split_orders(s):\n",
    "    s = s.strip()\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        s = s[1:-1]\n",
    "    orders = []\n",
    "    current = \"\"\n",
    "    paren_count = 0\n",
    "    for char in s:\n",
    "        if char == \"(\":\n",
    "            paren_count += 1\n",
    "        elif char == \")\":\n",
    "            paren_count -= 1\n",
    "        if char == \",\" and paren_count == 0:\n",
    "            orders.append(current.strip())\n",
    "            current = \"\"\n",
    "        else:\n",
    "            current += char\n",
    "    if current.strip():\n",
    "        orders.append(current.strip())\n",
    "    \n",
    "    canon_orders = [canonicalize_drink_order(o) for o in orders]\n",
    "    merged = merge_drink_orders(canon_orders)\n",
    "    return \"[\" + \", \".join(merged) + \"]\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSWFR2mo__ut",
    "outputId": "c0f086f5-98d7-4e8c-b703-0a90952b4ee3"
   },
   "source": [
    "import json\n",
    "\n",
    "def calculate_accuracy_and_save_mismatches(json_file, output_file):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    total = len(data)\n",
    "    correct = 0\n",
    "    mismatches = []\n",
    "\n",
    "    for item in data:\n",
    "        output = split_orders(item['output'])\n",
    "        expected = split_orders(item['expected'])\n",
    "\n",
    "        if output == expected:\n",
    "            correct += 1\n",
    "        else:\n",
    "            print('\\n\\n')\n",
    "            print(output)\n",
    "            print(expected)\n",
    "            mismatches.append(item)\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(mismatches, outfile, indent=4)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "json_file = f'FoodOrderingDataset/output/Ablation_NER_Coffee_Results_{model_name}.json'\n",
    "mismatch_file = f'FoodOrderingDataset/output/Ablation_NER_Coffee_Mismatches_{model_name}.json'\n",
    "\n",
    "accuracy = calculate_accuracy_and_save_mismatches(json_file, mismatch_file)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Mismatches have been saved to: {mismatch_file}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "new_acl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
